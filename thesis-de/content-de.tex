\section{Erklärung}
Hiermit erklären wir, dass wir die Arbeit selbstständig verfasst und und keine
anderen als die angegebenen Quellen und Hilfsmittel benutzt haben. Diese Arbeit
wurde keinem anderen Prüfungsausschuss in gleicher oder vergleichbarer Form
vorgelegt.

\vfill
{\centering
\renewcommand{\arraystretch}{0.9}
\begin{tabular}{p{0.25\textwidth}p{0.05\textwidth}p{0.25\textwidth}p{0.05\textwidth}p{0.25\textwidth}}
  \dotfill                    & & \dotfill                      & & \dotfill \\
  \centering\footnotesize{Tim Meusel}& & \centering\footnotesize{Marcel Reuter}& & \centering\footnotesize{Nikolai Luis}%
\end{tabular}
}

\newpage

\section{Einführung}
Das Heinrich-Hertz-Europakolleg Bonn verlangt im fünften und sechsten Semester
der Weiterbildung zum staatlich geprüften Informatiker eine fachbezogene
Projektarbeit. Dieses Projekt wird in Gruppen von zwei bis vier Personen
durchgeführt und soll fachliche Inhalte sowie Inhalte aus dem Projektmanagement
kombinieren. Es handelt sich um eine praktische Arbeit. Jeder Abschnitt enthält
ein Kürzel des Autors, hierbei bedeutet:
\begin{outline}
  \1 {[MR]} erstellt von Marcel Reuter
  \1 {[NL]} erstellt von Nikolai Luis
  \1 {[TM]} erstellt von Tim Meusel
\end{outline}
\tm%

\section{Projektvorstellung}
\label{subsubsec:projektvorstellung}
Cloud Provider bieten verschiedenste virtuelle Instanzen auf physischen Hosts
an. Dabei nutzt jeder virtuelle Server die vorhandenen Ressourcen des
physischen Systems unterschiedlich. Hier kommt es, aufgrund der
Mischkalkulation für die Ressourcen, zu einer Überbuchung (Overcommitment) des
Hosts. Weil das Monitoring nicht ausreichend ist, oder kein sinnvolles
Placement implementiert ist (Placement beschreibt den Algorithmus der einen
Node ermittelt auf dem eine neue virtuelle Instanz angelegt wird) kommt es
regelmäßig zu Performanceeinbußen. Für Kunden gibt es keine Transparenz über
die ihm zugeteilten und durch ihn genutzten Ressourcen, weshalb auch keine
ressourcenbasierte Abrechnung erfolgen kann. Teamleiter sind häufig mit der
Effizienzsteigerung der Plattform beschäftigt und müssen die Auslastung
steigern. Dies ist ohne detaillierte Auslastungsreports nicht möglich.

In diesem Projekt soll eine funktionierende Open Source Software entwickelt
werden, die sich in drei Teile gliedert:
\begin{outline}
  \1 Die verschiedenen Ressourcetypen (CPU Zeit / Datendurchsatz / RAM
  Auslastung / Speicher Auslastung / Netzwerkdurchsatz) der einzelnen
  virtuellen Server müssen in einem sinnvollen Intervall periodisch ermittelt
  werden.
  \1 Die Daten müssen aggregiert und gespeichert werden. Hierbei ist auf eine
  Skalierung auf mindestens 10.000 virtuelle Instanzen unter Berücksichtigung
  der Verfügbarkeit und Performance der Datenbank zu achten (Sharding oder
  Replikation, verteilt oder zentral, dokumentenbasiert oder relational).
  \1 Diese Daten können dann dem Endanwender präsentiert werden (\gls{API} und
  Web-UI). Hierzu wird eine Userstory Erhebung unter den drei Anwendertypen
  Kunde, Administrator, Manager bei Partnerunternehmen durchgeführt, um
  gewünschte Algorithmen zur Visualisierung zu ermitteln (zum Beispiel
  ermitteln von freien oder überbuchten Nodes, grafische Auswertung für Kunden).
\end{outline}

Dieses Projekt eignet sich besonders gut als Projektarbeit, da es in drei Teile
gegliedert ist. Jeder dieser Teile ist eigenständig und wird einem
Projektmitglied zugeordnet. Dies erleichtert die spätere Bewertung.
\tm%

\subsection{Projektteam}
Das Projektteam besteht aus den drei Mitgliedern Marcel Reuter, Nikolai Luis
und Tim Meusel.
\tm%

\subsubsection{Marcel Reuter}
Herr Reuter beendete 2013 seine Ausbildung zum IT-Systemelektroniker und
arbeitet seit dem bei der Firma EBF-EDV Beratung Föllmer GmbH. Er ist
verantwortlich für die visuelle Schnittstelle des Projekts (Punkt 3).
\mr%

\subsubsection{Nikolai Luis}
Herr Luis begann die Weiterbildung zum Techniker wärend seiner Ausbildung zum
Fachinformatiker Anwendungsentwicklung, welche er im Januar 2016 beendete. Er
arbeitet als BIG Data Analyst bei der Deutschen Telekom. Er ist verantwortlich
für die Speicherung der Daten und die automatisierte Schnittstelle (Punkt 2).
\nl%

\subsubsection{Tim Meusel}
Herr Meusel schloss seine Ausbildung zum Fachinformatiker Systemintegration
2012 ab. Aktuell arbeitet er als Systems Engineer bei der Host Europe Group.
Er verantwortet die Ermittlung sowie Übertragung der Daten.
\tm%

\subsection{Auftraggeber}
Die Ansprechpartner für dieses Projekt ist das Unternehmen Puppet Inc. (im
folgenden Puppet) in der Rolle als Auftraggeber, welches von den Mitarbeitern
Herrn David Schmitt und Herrn Steve Quin vertreten wird. Puppet ist Marktführer
im Bereich Konfigurationsmangement Software. Software dieser Art hilft es
Administratoren sehr einfach Testumgebungen aufzubauen und auch
Produktivumgebungen zu Verwalten. Das Kernprodukt der Firma Puppet, welches
ebenfalls puppet heißt, steht unter einer Open Source Lizenz und darf frei
genutzt werden. Der Einsatz der Software erlaubt es dem Projektteam
verschiedenste Prototypen in kurzer Zeit zu bauen. Puppet entwickelt außerdem
Software zum Testen. Dies vereinfacht das Qualitätsmanagement im Projekt.
Puppet hat in der Vergangenheit bewiesen, mit agiler Entwicklung und diversen
Testverfahren umgehen zu können, beides wird intensiv in deren Teams genutzt.
Herr Quin und Herr Schmitt bieten tiefgreifendes Wissen zu den verschiedenen
Programmen und Techniken, um das Projektteam zu untersützen und zu beraten.
\tm%

\subsection{Aktuelle Situation}
In der~\ref{subsubsec:projektvorstellung} wurden bereits die Intentionen des
Projekts erläutert. In der Vergangenheit wurde schon mal versucht eine passende
Softwarelösung zu entwickeln. OpenStack ist ein Softwareprojekt mit dem große
Mengen an Rechen- und Netzwerkkapazitäten, sowie persistenter Speicher in einem
Rechenzentrum zu einer \gls{Public Cloud} oder \gls{Private Cloud} Umgebung
zusammengefasst und orchestiert werden~\cite{OpenStack_Intro}. Eines der
Teilprojekte ist Telemetry. Das Ziel hiervon ist es, zuverlässig Daten von
physischen und virtuellen Ressourcen zu ermitteln verlässlich zu speichern. Die
Daten sollen zur Analyse genutzt werden und Aktionen auslösen wenn bestimmte
Kriterien erreicht sind~\cite{OpenStack_Telemetry}. Telemetry bringt leider
mehrere Nachteile mit sich:

\begin{outline}
  \1 Die Standarddatenbank für Telemetry war lange Zeit MongoDB. MongoDB ist
  eine dokumentenorientierte Datenbank, hier werden Daten nicht in Tabellen
  strukturiert sondern in eigenständigen Dokumenten. Jedes Dokument hat eine
  eigene Datenstruktur (z.B. im \gls{JSON}
  Format)~\cite{Dokumentenorientierte_Datenbank}. Dies ermöglicht es, die
  Datenbank sehr einfach vertikal zu skalieren. Hierbei werden alle Dokumente
  auf mehrere Server verteilt. Schreib- und Lese-Anfragen können ebenfalls auf
  alle Server verteilt werden. Die Skalierung ist nahezu
  linear~\cite{MongoDB_Architecture},~\cite{What_is_MongoDB}. Die Grundidee ist
  sehr gut und eignet sich für besonders große Datenmengen oder Installationen
  die Hochverfügbar sein müssen. Die Implementierung in MongoDB hat allerdings
  diverse Nachteile. Kyle Kingsbury hat intensiv MongoDB mit \gls{Jepsen}
  getestet. Die Datenbank hat sich mehrfach als sehr unzuverlässig
  herausgestellt~\cite{MongoDB_on_Jepsen}. Die beiden folgenden Punkte
  disqualifizieren MongoDB für einen Einsatz als persistenten  Datenspeicher,
  da die Persistenz nicht sichergestellt ist. Es wurde von Kyle Kingsbury
  bewiesen, das:
    \2 MongoDB bei einem Schreibvorgang bestätigt, das Daten persistent
    gespeichert wurden, dies allerdings nicht immer der Fall ist. Ein
    unbemerkter Datenverlust ist die Folge.
    \2 MongoDB in bestimmten Situationen die falschen Daten bei einer
    Leseanfrage zurückliefert.

  \1 Das Telemetry Projekt hat diese Probleme ebenfalls erkannt und nach
  alternativen Datenbanken gesucht. Nachdem keine vorhandene Lösung ihren
  Anforderungen entsprach, entschieden sie sich für die Entwicklung einer
  eigenen Datenbank: \gls{Gnocchi}. Diese Datenbank ist noch in der Entwicklung
  und noch nicht für den produktiven Einsatz bereit.
  \1 Es wird immer wieder von Skalierungsproblemen berichtet. Das CERN betreibt
  eine OpenStack Installation und konnte die Probleme mit Telemetry nur mit
  immenser Hardware lösen. Die Kosten für diese Infrastruktur als auch die
  Komplexität sind viel zu hoch. Sie übersteigen das Budget der meisten Cloud
  Umgebungen wodurch diese unwirtschaftlich werden~\cite{OpenStack_CERN}.
  \1 Das Telemetry Projekt ist sehr stark in OpenStack eingebunden. Der Einsatz
  in anderen Cloud Umgebungen ist nicht vorgesehen, da die einzelnen Dienste
  aus dem Telemetry Projekt weitere OpenStack Komponenten benötigen. Ein
  eigenständiger betrieb ohne OpenStack ist nicht geplant für die Zukunft.
\end{outline}

Aufgrund der langen Liste an Problemen ist Telemetry aktuell innerhalb einer
kleinen OpenStack Installation teilweise nutzbar, jedoch nicht wirtschaftlich
in großen Umgebungen oder außerhalb von Openstack. Es ist nicht davon
auszugehen, dass diese Probleme kurz- bis mittelfristig gelöst werden. Somit
entschied sich das Projektteam eine Alternative zu entwicklen die unkompliziert
zu installieren ist und unabhängig von OpenStack arbeitet.
\tm%

\subsection{Anforderungen}
Die Detailanforderungen werden getrennt für die drei Bereiche des Projekts im
folgenden Abschnitt beschrieben. Diese ergeben sich aus dem Lastenheft und
Pflichtenheft sowie aus den Userstories der Partner. Für Alle Lösungen gillt,
das sie eine aktive Community haben und unter einer Open Source Lizenz stehen.
\tm%

\subsubsection{Datenerfassungssysteme}
Unterschiedliche Ausbaustufen für virtuelle Machinen werden über mehrere
verschiedene Ressourcen, die sich in Ihrer Leistungsklasse unterscheiden,
differenziert. Diese Typen müssen für jede virtuelle Machine ausgelesen werden.
Als Referenz werden die Typen der größten deutschen Anbieter nachweis! für
virtuelle Machinen genommen. Diese sind aktuell:

Zugewiesener Arbeitsspeicher, Anzahl/Leistung der Prozessorkerne, Durchsatz des
Datenträgers, Anbindung an das Internet, nachweis via scrots fachwörter
referenz?

Diese Werte müssen sowohl in den virtuellen Machinen als auch auf dem Host
ermittelt werden können. Im Bereich Managed Hosting hat der Hoster Zugriff in
die virtuellen Instanzen und kann dort direkt sehr detailliert Daten ermitteln.
Im klassischen vServer Bereich (dem Bereitstellen des vServers als Produkt,
nicht als Service) hat der Betreiber keinen Zugriff in die VM und muss Daten
vom Host aus ermitteln. Auf dem Host muss zusätzlich Gesamtauslastung der
Ressourcen sowie der Zustand der Hardware ermittelt werden.

Gesammelte Daten müssen lokal zwischengespeichert werden können, um einem
Verlust bei Netzwerkstörungen zu vermeiden. Der Versand muss nach dem Push- und
nicht nach dem Polling-Verfahren arbeiten. Somit kann Eventbasiert gearbeitet
werden, dies verhindert Overhead im Netzwerk. Eine Visualisierung in Echtzeit
ist nicht gefodert weshalb Daten lokal zwischengespeichert werden können um sie
gebündelt zu verschicken.
\tm%

\subsubsection{Datenbanksysteme}

\subsubsection{Frontends}
Die Weboberfläche muss ausgewählten Benutzern eine Übersicht über die
verbrauchten oder freien Ressourcen, wie z.\,B.\ CPU Auslastung oder RAM
Auslastung einzelner virtueller oder physischen Maschinen bereitstellen.
Hierbei ist wichtig, dass die Sicherheit (Authentisierung, Authentifizierung
und Authorisierung) der Daten gewährleistet wird. Dies bedeutet, das sowohl die
Verbindung zwischen Datenbank und Weboberfläche gesichert sein muss, als auch
die Weboberfläche selber, gegen Zugriff von Unbekannten. Die Weboberfläche
greift hier mittels API Abfragen auf die Datenbank zu, dies ermöglicht uns den
Zugriff nur für das Frontend auf die Datenbank gewährleisten zu können.  Die
Weboberfläche soll Administratoren bei Neukonfiguration von virtuellen
Maschinen unterstützen und zeigt hier die Auslastung der einzelnen physischen
Systemen. Der Administrator kann so gezielt die einzelnen physischen Maschinen
besser auslasten und verteilen. Ebenfalls kann das Frontend eine Schnittstelle
für komplexe Abfragen und Analysen bereitstellen. Bei Bedarf können diese auch
visuell ausgegeben werden.
\mr%

\section{Projektmanagement}
Die Liste an verfügbaren Managementmethoden ist lang. Methoden wie PRINCE2 oder
Lean Management kommen aus dem Bereich des Projektmanagements und sind seit
vielen Jahren auch im Bereich der Softwareentwicklung vertreten. Hinzu kommen
Vorgehensmodelle aus der Softwareentwicklung selbst, wie das Wasserfallmodell
oder das Spiralmodell. In den letzten Jahren gab es einen Wandel hin zu agiler
Entwicklung. Es hat sich gezeigt, dass sich in der schnelllebigen
Informationswelt Anforderungen an Software regelmäßig ändern, auch während der
Entwicklungs- und Planungsphase und nicht erst im späteren Betrieb. Außerdem
gibt es in den meisten Projekten unvorhergesehene Zwischenfälle. Dazu gehören
unter anderem:

\begin{outline}
  \1 Sicherheitslücken in verwendeten Bibliotheken werden entdeckt. Diese
  müssen oftmals aufwendig aktualisiert werden.
  \1 Die Zeiteinschätzung für die Implementierung von Funktionen oder die
  Behebung von Fehlern benötigt wesentlich mehr oder weniger Zeit als
  geschätzt.
\end{outline}

Die Techniken und Vorgehensweisen der agilen Softwareentwicklung versuchen dem
entgegenzubeugen. Sie zeichnen sich dadurch aus, dass sie:

\begin{outline}
  \1 Iterativ arbeiten
  \1 Einen sehr geringen bürokratischen Mehraufwand besitzen
  \1 Sich flexibel an das Projekt und an Änderungen anpassen
\end{outline}

Die Firma Puppet entwickelt seit mehreren Jahren erfolgreich Software. Sie
steht dem Projektteam mit hilfreichen Tips und Schulungen zur Seite. ``Agile
Softwareentwicklung'' gilt als Oberbegriff für alle Techniken und
Vorgehensweisen in dem Bereich. Das Softwareentwicklungsmodell Scrum nutzt
Teile der agilen Softwareentwicklung. Das Projektteam entschied sich für die
Nutzung agiler Projektmanagement Methoden da diese in der Wirtschaft aktuell am
verbreitetsten sind.
\tm%

\subsection{Scrum}
Scrum ist zu unflexibel für ein Technikerprojekt. Die Methode schreibt vor,
dass man alle Techniken von Scrum nutzen muss und diese nicht abgewandelt
werden dürfen.  Unter anderem wird ein ``Daily Standup'' verlangt. Dies ist
eine Besprechung an jedem Arbeitstag, welche genau 15 Minuten lang ist. Die
Zeit muss gleichmäßig auf alle Teilnehmer verteilt werden. Aufgrund der
Vollzeitbeschäftigung aller Mitglieder in Kombination mit dem
Abendschulunterricht erfolgen viele Arbeiten am Projekt asynchron. Die
Durchführung von täglichen Besprechungen ist nicht
praktikabel.~\cite{scrum_talk}
\tm%

\subsection{Agile Vorgehensweise im Projekt}
\label{subsec:agile_vorgehensweise}
Die Projektzeit wird in zweiwöchige Abschnitte, Sprints genannt, eingeteilt. Am
Anfang jedes Sprints erfolgt ein Rückblick auf den vergangenen Sprint. Es wird
kurz besprochen was besonders positiv oder negativ lief, und ob die
Projektmitglieder zufrieden sind. Im Anschluss folgt die Planung für den
kommenden Sprint. Es wird überlegt welche Arbeit erledigt werden muss, und
deren ungefährer Zeitaufwand geschätzt. Für jede Aufgabe wird ein Ticket in
der Projektmanagementsoftware erstellt. Das Projektteam hat sich für ``JIRA''
entschieden, da dies aktuell am verbreitesten in der Wirtschaft ist. Neue
Featurewünsche werden als Userstory angelegt. Dies ist ein Ticket in dem aus
Sicht der anfragenden Person ihr Wunsch beschrieben ist. Für wichtige
Ereignisse werden Meilensteine festgelegt.
\tm%

\section{Schnittstellen im Projekt}
Zwischen den Softwarekomponenten im Projekt werden Daten ausgetauscht. Dies
erfolgt über definierte Schnittstellen (auch Interfaces genannt). Im folgenden
sind die einzelnen Schnittstellen zwischen den Komponenten und von den
Komponenten nach außen erklärt.
\tm%

\subsection{Datenerfassungssysteme}
Die Datenerfassungssysteme stellen zwei Schnittstellen zur Verfügung. Sie
kommunizieren mit dem lokalen System über eine
\glslink{Bidirektional}{bidirektionale} Schnittstelle. Die Datenerfassung wird
für die meisten Ressourcetypen über Polling realisiert. Hierzu fragt das
Datenerfassungssysteme periodisch die Schnittstelle des Hosts nach neuen Daten.
Abfrageschnittstelle des Hosts wird durch den Linuxkernel bereitgestellt, von
ihr kann ausschließlich gelesen werden. Die Erfassungsysteme arbeiten
zusätzlich eventbasiert. Hierbei schickt der Kernel die neuen Informationen
direkt zur Schnittstelle der Datenerfassungssysteme. Der Kernel ist der
kritischste Teil eines laufenden Computers. Er hat volle Rechte auf alle
Hardwareschnittstellen, weshalb die Interaktion mit ihm besonders geschützt und
minimal sein muss. Programmierfehler in der Vergangenheit erlaubten es mehrfach
auf Schnittstellen auf den Kernel zu schreiben, obwohl das Interface nicht
beschreibbar sein sollte. Der Kernel selbst bietet nur lokale Schnittstellen,
aber über weitere Software werden diese indirekt im Netzwerk bereitgestellt.

Die zweite Schnittstelle der Datenerfassungssysteme ist projektintern und
interagiert mit der Datenbank. Diese Schnittstelle ist aus Sicherheitsgründen
\glslink{Unidirektional}{unidirektional} um den Kernel zu schützen. Die
Erfassungssysteme können also nur Daten über das Netzwerk verschicken, jedoch
akzeptieren Sie keine Anfragen, welche über die Netzwerke eingehen.

Bei beiden Schnittstellen der Datenerfassungssysteme handelt es sich um eine
Binärschnittstelle. Hierbei werden Daten nicht in einer für Menschen lesbaren
Form übertragen, sondern in einem Binärprotokoll. Diese Protokolle sind
besonders effizient in der Datenübertragung und Datenverarbeitung. Es ist nicht
erforderlich, das Menschen mit den beiden Schnittstellen kommunizieren.

\subsection{Datenbanksystem / API}

\subsection{Frontend}

\section{Analyse von Softwarekomponenten}
\subsection{Datenerfassungssysteme}
Im Abschnitt XXX wurde bereits auf die einzelnen Ressourcetypen eingegangen,
welche erfasst werden müssen. Um die verschiedenen Datenerfassungssysteme im
Hinblick auf die Ressourcetypen zu evaluieren, muss zunächst geklärt werden was
eine Metrik, ein Trend und eine Timeseries ist.

\subsubsection{Begriffsklärung}
Eine Metrik ist die Kombination aus:

\begin{outline}
  \1 Der Wert eines bestimmten Ressourcetypen zu einer bestimmten Zeit
  (Momentaufnahme).
  \1 Der Zeitstempel der Aufnahme
  \1 der Name des Ressourcetypen
\end{outline}

Eine Metrik wird periodisch als Ganzzahl ermittelt. Die Kombination mehrerer
Werte einer Metrik ergibt eine Timeseries (auch ``Datenreihe'' oder ``Abfolge''
genannt). Um Speicherplatz zu sparen können die Werte aggregiert werden.
Hierbei wird für einen bestimmten Zeitraum einer Timeseries die Werte genommen
und folgende Funktionen angewendet:

\begin{outline}
  \1 min(): Ermittlung des niedrigsten Wertes
  \1 max(): Ermittlung des höchsten Wertes
  \1 count(): Addieren aller Werte
  \1 sum(): Alle Werte werden aufaddiert. Diese Berechnung ist nicht bei jedem
  Ressourcetyp sinnvoll, allerdings wird das Ergebnis für weitere Berechnungen
  benötigt
  \1 avg(): Berechnung des Durchschnitts mit den Ergebnissen aus count() und
  sum()
  \1 95pct(): Berechnung des Durchschnitts, zuvor werden Die Werte nach größe
  sortiert und die höchsten 5\% ignoriert.
\end{outline}

Danach werden nur die Ergebnisse einer oder mehrer Funktionen gespeichert und
die eigentlichen Daten verworfen. Das Aneinanderreihen mehrerer aggregierter
Werte bildet einen Trend (auch History Trend genannt). Trends werden oftmals
visualisiert. Hierbei lässt sich Ressourcensparend ein langer Verlauf der
Metrik erkennen. Basierend auf vorhandenen Trends kann auch eine ``Trend
Prediction'' erstellt werden. Hierbei werden Daten der Vergangenheit analysiert
und auf eine mögliche Zukunft vorrausgerechnet.

``Tiered Trends'' bezeichnet eine Datensammlung auf welche mehrfach die oben
genannten Funktionen angewendet wurde. Die benötigte Granularität ändert sich
oftmals mit dem Alter der Daten. Beispiel: In den ersten 24h benötigt man Daten
mit einer Auflösung von 30 Sekunden. In den Darauffolgenden 2 Wochen reichen
Trends mit einer Auflösung von 5 Minuten und für die folgenden 3 Monaten reicht
eine Auflösung von 30 Minuten.

Hier nimmt man sich Daten die älter als 24 Stunden sind und teilt diese in
Einheiten von 5 Minuten. Hierauf werden die Funktionen angewendet, die
originalen Daten gelöscht und die Ergebnisse gespeichert. Parallel wird
regelmäßig nach bereits vorhandenen Trends geprüft, welche älter als 2 Wochen
sind. Diese Werden wieder in Einheiten von 30 Minuten aufgeteilt und die
Funktionen erneut angewendet. Somit wurden ``Tiered Trends'' gebildet.

Das bilden von Trends kann schon während der Datenerfassung erfolgen, indem die
gesammelten Werte lokal zwischengespeichert werden und ausschließlich die
gebildeten Trends zur Datenhaltung geschickt werden. Dies ist besonders
effizient, da jeder Server nur eine geringe Menge an Trends zu berechnen hat.
Es ist jedoch erforderlich, dass der Client alle Daten zumindest so lange
vorhält, bis alle benötigten Trends gebildet sind, im obigen Beispiel zu
``Tiered Trends'' sind dies 2 Wochen. Oftmals gibt es die Anforderung Trends
Ad hoc zu bilden oder die Intervalle regelmäßig zu verändern. Hierzu muss eine
neue Konfiguration für die Datenerfassungskomponente auf jedem Server erstellt
werden, da diese keine automatisierte Schnittstelle bieten.

Ebenfalls kann die Generierung der Trends auf dem Datenbanksystem erfolgen.
Dies benötigt Rechenkapazitäten, bringt aber diverse Vorteile:

\begin{outline}
  \1 Trends können nicht nur über eine Metrik eines Servers erstellt werden,
  sondern auch über mehrere Server hinweg.
  \1 Trends können erstellt werden, wenn diese angefordert werden
  (Eventbasiert)
  \1 Trends können über verschiedenste Zeitrahmen erstellt werden. Außerdem
  lässt sich dieser einfacher ändern, da er nur zentral konfiguriert ist und
  nicht auf jedem Server,
\end{outline}

Aufgrund der Flexibilität der Trendgenerierung auf der Datenbank entschied sich
das Projekteam dazu, die Generierung von den Servern auf die Datenbank zu
verlagern. Die Fähigkeit Trends generieren zu können ist somit kein
Evaluationskriterium für Datenerfassungssysteme.

\begin{outline}
  \1 collectd mit Virt Plugin
  \1 coreutils
  \1 zabbix-agent
  \1 python-diamond
  \1 sysstat
  \1 atop
  \1 logtash
  \1 riemann
\end{outline}
\tm%

\subsection{Datenbanksysteme}
\label{subsec:datenbanksysteme}
Zu Beginn des Projektes musste das Projektteam mögliche Datenhaltungssysteme in
einer Liste für eine darauffolgende Evaluierung definieren. Bei der Erstellung
dieser Liste wurden Systeme aufgenommen, welche den Projektmitgliedern aus
vergangenen Projekten, beziehungsweise aus dem täglichen Arbeitstag bereits
bekannt waren. Zusätzlich hatten die Projektmitglieder vorab mit Experten aus
dem eigenen Unternehmen und aus dem Unternehmen des Auftraggebers über mögliche
weitere Systeme gesprochen.  Dadurch das Herr Luis in dem Bereich der
Massendatenhaltungssysteme arbeitet, sind ebenfalls Systeme aufgenommen worden,
welche im Bereich der sogenannten Big Data Technologie arbeiten.

Das hinzufügen von weiteren/neuen Datenbanksystemen zur späteren
Evaluierung erfolgt nur nach einer Genehmigung vom Auftraggeber.

Die in der Liste aufgenommen Systeme sind folgende:
\begin{outline}
  \1 elasticsearch
  \1 cassandra
  \1 postgres
  \1 OpenTSDB
  \1 KNIME
  \1 impala
  \1 hadoop
  \1 hive
\end{outline}
\nl%

\subsubsection{Vorbereitung der Evaluierung}
\label{subsubsec:DBS_vorbereitung_der_evaluierung}
Als Vorbereitung für die Evalution der Datenhaltungssysteme wurden mehrere
Kriterien definiert, welche einen Leitpfaden für die spätere Arbeit geben.
Während der Auswahl und Definition der von dem Datenbanksystem zu erfüllenden
Kriterien wurde darauf geachtet, dass diese sich aus dem späteren Zielsystem
ableiten lassen und ebenfalls realistisch erfüllbar sind. Anschließend wurde
die Relevanz jedes Kirteriums von den Teammitgliedern beurteilt und festgelegt.

Die daraus resultierten Kriterien sind nun nach Relevanz absteigend
aufgelistet:
\begin{outline}
  \1 Bereits vorhandenes Wissen über die Datenbank. Dazu gehört, dass diese
  eine umfangreiche Dokumentation besitzt und eine aktive und große Community
  für Diskussionen und Fragen vorhanden ist. Ebenfalls fallen die vorhandenen
  Vorkenntnisse über das Datenbanksystem der Projektmitglieder, sowie die
  Mitarbeiter von dem Unternehmen des Auftraggebers unter dieses Kriterium. Es
  ist wichtig, dass die zu aufwendene Einarbeitungszeit während dem Projekt und
  im späteren Wirkbetrieb bei Mitarbeitern des Unternehmens so gering wie
  möglich gehalten wird.
  \1 Das Datenhaltungssystem muss einfach, schnell und jederzeit erweiterbar
  sein. Dies bedeutet, dass Ressourcen (CPU/RAM/Speicherplatz) des
  Datenbanksystems im optimalsten Fall während dem normalen Betrieb (kein
  Neustart oder Auszeit) aufgestockt werden kann. Es ist jedoch nach
  Anforderung des Auftraggebers ausreichend, wenn eine Aufstockung nach einer
  Auszeit von maximal 45 Minuten erfolgt ist.
  \1 Umweltschonende und effiziente Datenhaltung ist zu beachten. Dies
  definiert eine optimale Relation zwischen der verwendeten Hardware und dem
  daraus resultierendem Ergebnis. Eine umweltschonende Datenhaltung kann
  unabhängig der korrekten Auswahl der genutzten Stromeffiziensklasse jedes
  Hardwarebauteils bereits bei der im Wirkbetrieb zu benutzende Software
  beeinflusst werden.  Dies ist im Bereich der Datenhaltungs-Software die
  entstehende Speicherplatzgröße für einen einzelnen Datensatz in einer
  Datenbank. Um so kleiner dieser ist, desto mehr kann bei Energiekosten für
  zusätzlichen Speicherplatz eingesparrt werden.

  Unter Berücksichtigung der genannten Attribute, soll jedoch die
  Datenhaltungs-Software mit der gleichen Hardware-Ressource das beste und
  schnellste Ergebnis erbringen können. Dies bedeutet, dass auch bei komplexen
  Analysetechniken und zusätzlich hohen Datenmengen, dass System weiterhin
  gegenüber anderen Datenhaltungssystemen ein valides und schnelles
  Analyseergebnis erbringen kann.
  \1 Die Datenhaltungs-Software sollte bereits Methoden zur Datensicherung
  besitzen. Dabei ist zum einem eine Backup Methode, und zum anderen das
  Verhalten bei Problemen am System, zum Beispiel ein Defekt am Netzwerkkabel,
  mit inbegriffen.
\end{outline}
\nl%

\subsubsection{Durchführung der Evaluierung}
\label{subsubsec:durchfuehrung_der_evaluierung}
Bei der Durchführung der Evalution von den ausgewählten Datenhaltungssystemen
aus der Liste in Punkt~\ref{subsec:datenbanksysteme} wurden die
Evalutionskriterien aus Punkt~\ref{subsubsec:DBS_vorbereitung_der_evaluierung}
verwendet. Diese dienten als Leitpfaden für jedes Datenhaltungssystem und
wurden von jedem Projektmitglied beachtet.

Zu Beginn der Durchführung teilte Herr Meusel als Projektleiter die zu
evaluierenden Datenhaltungssysteme jedem Projektmitglied zu, um eine schnellere
Bearbeitung zu gewährleisten. Bei der Einteilung wurden die bereits vorhandenen
Erfahrungen jeder Projektmitglieder zu dem jeweiligen Datenhaltungssystem
berücksichtigt. Im zweiten Schritt sollte sich anschließend jedes
Projektmitglied mit dem zugeteilten Dantenhaltungssystem kurz
auseinandersetzen. In diesem Schritt ist Herrn Luis aufgefallen, dass es sich
bei der in der Liste aufgenommenen Software ``KNIME'' nicht um ein
Datenhaltungssystem handelt, sondern um ein Werkzeug zur Datenanalyse,
Datenaufbereitung und Datendarstellung.

Die daraus resultierenden Ergebnisse wurden Herrn Luis anschließend von den
Projektmitgliedern bereitgestellt, sodass dieser einen Überblick im
Projektbereich ``Datenhaltung'' erschaffen konnte. Die resultierenden
Ergebnisse und Erkenntnisse sind in dem nachfolgenden Punkt für jede
Datenhaltungs-Software dokumentiert.
\nl%

\paragraph{Elasticsearch}
\label{paragraph:elasticsearch}
Some Text here!
\nl%

\paragraph{Cassandra}
\label{paragraph:cassandra}
Some Text here!
\nl%

\paragraph{Postgres}
\label{paragraph:postgres}
Postgres, oder auch PostgreSQL genannt, ist ein \gls{SQL} basiertes \gls{DBMS}.
Die initiale Arbeit an Postgres begann 1986~\cite{old_postgres}. Mit über 30
Jahren Entwicklung ist es eines der ältesten und am weiten verbreitetsten
DBMS~\cite{db_ranking}. Es steht unter einer eigenen Open Source Lizenz und
darf frei genutzt werden~\cite{postgres_license}. Die Community ist sehr aktiv,
sie pflegt ein komplexes Wiki~\cite{postgres_wiki} sowie ein eine eigene Seite
mit Anleitungen für Einsteiger und Optimierungshilfen für
Fortgeschrittene~\cite{postgres_tutorial}.

\lstinputlisting[language=bash]{postgres-clone.txt}

Wie im in der obigen Shellausgabe zu sehen, enthäl das Git Repository des
Postgres Quellcodes am 26.11.2016 41366 einzelne Commits von 41 verschiedenen
Autoren. Aufgrund der Patchpolitik von Postgres werden Patches oftmals an
Autoren aus dem Postgres Team geschickt, ein Teammitglied fügt danach den Patch
in das Repository ein. Somit lässt sich nicht genau bestimmen von wie vielen
Leuten Code beigesteuert wurde.

Die Postgres Architektur sah lange Zeit vor, dass der Dienst auf einem einzigen
Server betrieben wird. Mittlerweile gibt es mehrere Möglichkeiten die
Architektur anzupassen um Postgres:

\begin{outline}
  \1 \glslink{Hochverfügbarkeit}{Hochverfügbar} zu betreiben
  \1 \glslink{Skalierung}{Vertikal zu skalieren}
  \1 mit einer Verteilung der Anfragen den einzelnen Server zu entlasten
\end{outline}

Postgres bietet die Möglichkeit der \gls{Streaming Replication}. Hierbei wird
nach dem \gls{Active-Passive Prinzip} 1-N gearbeitet. Dies bietet zwei
Vorteile:

\begin{outline}
  \1 Leseanfragen können an passive Server gestellt werden.
  \1 im Fehlerfall oder für Wartungsarbeiten kann von einem aktiven auf einen
  beliebigen passiven Server umgeschaltet werden.
  \1 Hochverfügbarer Betrieb der Datenbank.
\end{outline}

Der aktive Server muss somit nur noch Schreibanfragen beantworten. Das
Hinzufügen von passiven Nodes oder das umschwenken der Schreibanfragen auf
einen von Ihnen kann im laufenen Betrieb erfolgen. Die Postgres Konfiguration
lässt sich zur Laufzeit anpassen um dem Dienst mehr Ressourcen des physischen
Hosts zuzuweisen.

Mit den Erweiterungen \gls{Pgpool-II} und \gls{Postgres-XC} kann ebenfalls ein
hochverfügbarer Betrieb realisiert werden. Außerdem ermöglichen sie eine
vertikale \gls{Skalierung}. Mehrere Server können hier zu einem Verbund
zusammengeschaltet werden. Schreibanfragen können von mehreren Servern
beantwortet werden. Wenn es gewünscht ist, kann jeder Server alle Daten
vorhalten, somit beeinträchtigt der Ausfall eines Servers nur die
Gesamtperformance, führt aber nicht zu einem Ausfall des Setups
(Shared-Nothing-Architektur).
\tm%

\paragraph{OpenTSDB}
\label{paragraph:opentsdb}
Some Text here!
\nl%

\paragraph{Hadoop / Hive /Impala}
\label{paragraph:hadoop_hive_impala}
Das Apache Hadoop System wird zum aktuellen Zeitpunkt bei
großen und leistungsfähigen Datenhaltungssystemen eingesetzt, sodass es
auch oftmals in Verbindung mit den Worten ``BIG DATA'' genannt wird.

Es handelt sich dabei um eine Vielzahl von Komponenten, bestehend aus mehreren
Frameworks und Ökosystemen, also im Klartext eine Reihe von frei wählbaren
Bibliotheken zur Definition der Datenhaltungslandschaft. Apache Hadoop verfolgt
dabei den Ansatz, alle Dateninformationen in nur einem gebündelten System zu
verwalten und keine zusätzlichen Datenhaltungssysteme, welche gegebenenfalls
nur auf eine einzelne Anforderung spezialisiert sind, zu gründen.

Um diesen Ansatz zu erfüllen, wurde das Clusterkonzept eingesetzt, Hadoop nennt
es selber ``Hadoop Distributed File System'' (HDFS).  Dabei werden die Daten in
der Datenhaltung nicht mehr auf einem einzelnen physischen System gehalten,
sowie vor einem Hardwareausfall gesichert, sondern nun auf mehrere Systeme
verteilt. Hadoop teilt dabei jedem in dem Cluster hinzugefügten System eine
spezielle Aufgabe zu. Für die Datenspeicherung existieren dabei drei
Aufgabenfelder. Nummer Eins ist der Data Node, dieser besteht oftmals aus
mehreren Festplatten und einer Netzwerkanbindung. Auf diesem wird eine
Datensatz mehrmals auf verschiedenen Festplatten abgespeichert, sodass bei
einem Ausfall der Datensatz gesichert ist. Es können bei Hadoop beliebig viele
Data Node's in der Datenhaltungslandschaft eingesetzt werden, so mehr Data
Node's, umso mehr Speicherplatz steht zur verfügung. Nummer Zwei ist der Name
Node, bei diesem handelt es sich um ein einzelnes System, welches den
Speicherort (Data Node ID), von einem Datensatz bereitstellt. Die letzte
Aufgabe erfüllt der Backup Node, auch bei diesem handelt es sich um ein
einzelnes System. Das System kommt zum Einsatz, wenn der Name Node ausfallen
sollte. Er synchronisiert sich dauerhaft mit dem Name Node, um jederzeit zum
Einsatz zu kommen.

Für das managen des Clusterkonzepts und zeitbasierenden Aufgaben (im
englischen: Job scheduling) wurde ``Hadoop YARN'' gegründet. Dieses gibt den
Nodes vor, welche Daten mit welchem Node ausgetauscht werden und wo die
einzelnen Backups stattfinden sollen. Es definiert dabei auch zu welchem
Tageszeitpunkt einzelne Aufgaben erfüllt werden sollen.  Diese Definitionen
können von dem System automatisch definiert werden, jedoch auch von einer
Person manuell eingestellt und verwaltet werden.

Für die Anbindung späterer Systeme und Methodiken der Datenanalyse, wird
``Hadoop Common'' eingesetzt. Es handelt sich dabei um ein reines
Schnitstellen-Modul, welches standartisierte Protokolle implementiert und
betreibt. Es ermöglicht zum Beispiel die Anbindung der Software ``Hive'' und
``Impala'', welche in den Punkt~\ref{paragraph:hadoop_beschreibung}
und~\ref{paragraph:impala_beschreibung} erläutert werden.

Für die Bearbeitung und Analyse von zeitkritischen Daten kommt die Komponente
``Hadoop Map Reduce'' zum Einsatz. Diese ist von dem gleichnamigen
Programmiermodell abgeleitet. Es handelt sich dabei um eine Hadoop-YARN
basiertes System, welches ein parallel abarbeiten von Aufgaben ermöglicht.
Dabei können Analyseanfragen nun nicht mehr nur in einzelne Server-Threads
aufgeteilt werden, sondern auch auf mehrere Data Nodes. Dies ermöglicht ein
schnelles und effizientes Management von Datenabfragen. Gleichzeitig besitzt
diese Komponente einen Data Node, welcher aus reinem Arbeitsspeicher besteht.
Arbeitsspeicher ist bis dato einer der schnellsten Speichermedien und kommt bei
zeitkritischen Datenabfragen zum Einsatz.

Diese vier Komonenten bilden den ``Hadoop Core'', welcher zwingend für den
Betrieb eines Hadoop Systems benötigt wird. Hadoop basierende Systeme, zur
Erfüllung von verschiedene und spezialisierten Aufgaben, werden unter dem
``Hadoop Ecosystem'' zusammengefasst. Eine vollständige Liste von Haddop
basierenden Systemen und Projekten kann hier entnommen
werden~\cite{Hadoop_related_projects}.
\nl%

\paragraph{Beschreibung Hive}
\label{paragraph:hadoop_beschreibung}
Stellt Schemas bereit (DWH) - Some more Text here
\nl%

\paragraph{Beschreibung Impala}
\label{paragraph:impala_beschreibung}
Realtime SQL working with Hadoop Map Reduce - Some more Text here
\nl%

\paragraph{Evaluierungsbericht}
\label{paragraph:hadoop_hive_impala_evaluierung}
Das ganze ist kacke weil zu viel - Some more Text here
\nl%


\subsection{Schnittstelle - Datenbereitstellung}
\label{subsec:schnittstelle_datenbereitstellung}
Neben der herkömmlichen Methode zur Datenabfrage von Datenbank-Systemen über
einen Datenbanktreiber, existiert noch die Möglichkeit einer API.

Die Verwendung von einer API Schnittstelle besitzt Nachteile, sowie Vorteile
beziehungsweise verbirgt gewisse Gefahren in Hinsicht auf den späteren Einsatz
im Produktivsystem. Eine dieser Gefahren ist das vernachlässigen der
Dokumentation einer API. Dadurch, das während der Entwicklung einer API bereits
definiert wird, welche Fähigkeiten und Methodiken die API besitzen soll, ist
eine nicht vorhandene oder unvollständige Dokumentation suboptimal. Darum muss
bei der Auswahl des genutzen API Systems darauf geachtet werden, dass die
Dokumentation von Softwarekomponenten für den Entwickler so einfach wie möglich
erfolgt.

Wenn die Dokumentation einer API vollständig und das ausführende System den
Performance-Anforderungen gerecht ist, bringt die Nutzung von einem API System
Vorteile. Darunter ist eine bessere Verwaltung von Zugriffsrechten und somit
auch gleichzeitig eine Verbesserung der Systemsicherheit. Durch den vorab
festgelegten Funktionsumfang der API kann der Systeminhaber geziehlt
kontrollieren, welche Inhalte ein Benutzer sehen oder modifizieren kann. Dabei
können grobe Einschränkungen, wie das Lesen oder Schreiben auf der gesamten
Datenbank, oder auch detaillierte Einschränkung, wie das Lesen oder Schreiben
von einer einzelnen Tabelle in der Datenbank, kontrolliert werden. Anders wie
bei der Verbindung über einen Datenbanktreiber kann bei der API der potentielle
Angreifer keine eigenen Datenbankbefehle definieren und ausführen. Somit wird
das Risiko der Datenmanipulation durch eine zusätzliche Schicht(Layer)
veringert.

Oftmals werden Daten nicht in der Struktur benötigt, in der sie gespeichert
sind. Die Möglichkeiten einer Transformation auf Datenbankebene sind sehr
begrenzt, eine API Schnittstelle in einer Hochsprache bietet hier deutlich mehr
Möglichkeiten.
\nl%

\subsubsection{Vorbereitung der Evaluierung}
\label{subsubsec:api_vorbereitung_der_evaluierung}
Anders wie bei der Evalierung der Datenbanksysteme wurde bei der Evaluierung
der möglichen API Systeme keine Liste im voraus erstellt. Dies lag daran, dass
keiner der Projektmitglieder oder Interessenten an dem Projekt Erfahrungen mit
API Systemen im vorhinein besitzen.

Aufgrund dessen wurde entschieden, eine Liste von Anforderungen an das
API System zu erstellen und im Anschluss während der Evaluierungsphase
Softwarelösungen zu suchen, welche die Anforderungen am besten erfüllen kann.

Die festgehaltenen Anforderungen sind nun nach Relevanz absteigend aufgelistet:
\begin{outline}
  \1 Die API Software muss auf einer selbst administrierten Hardware-Umgebung
  betrieben werden können. Das verwenden von einem fertigen API Softwarepaket
  von einem Cloudanbieter, bei welchem der Administrator alle Konfigurationen
  über ein Web-Interface des Providers vornimmt und der Cloudanbieter die
  vollständige Hardware-Umgebung administriert, ist ein absolutes
  Ausschlusskriterium. Es ist vorgehsehen, dass das API System möglichst nah an
  dem Datenhaltungssystem liegt, um mögliche Latenzen zwischen den beiden
  Systemen so niedrig wie möglich zu halten. Zudem sollen externe Cloudanbieter
  keinen Zugriff auf die teilweise Kundenbezogenen Daten der Datenhaltung
  erhalten. Zudem kann während dem Projekt entschiedenen werden, dass das
  Datenhaltungssystem nicht von externen Systemen erreichbar sein soll, sodass
  die damit verbundene Lösung über einen Cloudprovider nicht möglich wäre.
  Externe Systeme sind in diesem Projekt Geräte, welche außerhalb des
  Unternehmens betrieben werden.
  \1 Die API Software muss vollständig konfigurierbar und administrierbar sein.
  Entsprechend soll die Software nur eine leere Hülle mit Standardfunktionen
  einer API zur Verfügung stellen. Eine Konfiguration von einzelnen Parametern
  ist dabei erwünscht. Zu diesem Parametern gehört als Beispiel der Port, auf
  welchem das API System betrieben und von anderen Systemen erreicht werden
  kann. Zur Hilfe der admnistration soll das API System ein Framework für
  Entwickler bereitstellen. Mit diesem können wir als Projektmitglieder
  anschließend die Logik in das System implementieren und somit definieren
  welche Funktionen die API ausüben darf. Ein Framework in einer bekannten
  Entwicklersprache ist dabei erwünscht. Dies hat den Vorteil, dass der
  zuständige Entwickler im Projekt keine weitere Einarbeitungszeit für die neue
  Entwicklersprache benötigt.
  \1 Das API System sollte innerhalb des Projektes keine Kosten verursachen.
  Dazu gehören Lizenzkosten sowie laufende Betriebskosten bei externen
  Cloudanbietern. Spätere Kosten bei dem Auftraggeber sind in dieser
  Anforderung nicht mit inbegriffen. Grundsätzlich gillt für das ganze Projekt,
  dass nur Software mit einer Open Source Lizenz genutzt werden darf.
  \1 Die Erstellung von späteren Anwendungshandbüchern der API, soll dem API
  Entwickler so einfach wie möglich fallen. Eine sehr beliebte
  Dokumentationsmöglichkeit ist dabei das dokumentieren von wichtigen
  Informationen direkt in dem Quellcode des API Systems. Entwickler können
  dabei über die Kommentierungs-Funktion der jeweiligen Entwicklersprache eine
  Beschreibung sowie Ein- und Ausgabe von Werten festlegen. Diese werden im
  Anschluss während dem Kompiliervorgang in einem struktierten Dokument
  festgehalten und neben der eigentlichen API Software mit ausgeliefert. Dieses
  seperate Dokument ist oftmals in Form einer HTML oder PDF und kann auf
  gängigen Computersystemen eingesehen werden. Die beschriebene oder ähnliche
  Dokumentationsmöglichkeit sollte die API Software zur Verfügung stellen.
  Alternativ kann auch erst die Dokumentation geschrieben werden und darauf
  basierend Quellcode generiert werden. Beide Verfahren nennt man ``One Source
  of Truth Prinzip''. Hierbei wird sichergestellt, das es nur eine autoritative
  Quelle gibt, und der zugehörige Pendant auf der Quelle beruht. Dies vermeidet
  Dokumentation die nicht mit den eigentlichen Funktionen der Software
  übereinstimmen.
  \1 Bereits vorhandenes Wissen über das API System. Dazu gehört, dass diese
  eine umfangreiche Dokumentation besitzt und eine aktive und große Community
  für Diskussionen und Fragen vorhanden ist. Die dazugehörige
  Programmiersprache der API sollte ebenfalls für die Projektmitglieder
  nachvollziehbar sein, sowie eine umfangreiche Dokumentation und aktive
  Community für Diskussionen und Fragen besitzen.
\end{outline}
\nl%

\subsubsection{Durchführung der Evaluierung}
\label{subsubsec:api_durchfuehrung_der_evaluierung}
Bei der Evaluierung der API Systeme wurden die in
Punkt~\ref{subsubsec:api_vorbereitung_der_evaluierung} festgehaltenen
Anforderungen der API als Leitlinie für die Durchführung verwendet. Als ersten
Schritt wurde zunächst Recherche betrieben, damit das Projektteam einen
allgemeinen Eindruck über die aktuelle Marktsitutation zu API Systemen erhält.
Dabei wurden im Internet mehrere Blogs, Foren sowie Artikel von
Fachzeitschriften gelesen.  Die dort angesprochenen API Systeme wurden
anschließend mit den bereits definierten Anforderungen abgeglichen und
aussortiert. Dabei stellten die Projektmitglieder fest, dass die meisten API
Systeme von Cloudprovidern nur in bereits vorkonfigurierten Paketen mit einem
monatlichen Festpreis angeboten werden.  Beides ist ein absolutes
Ausschluskriterium für den späteren Wirkbetrieb sowie Nutzung der Software.
Ebenfalls wurde bei den vorkonfigurierten Paketen eine eigene Definition von
Funktionen komplett verboten. Lediglich ein einzelner Cloudprovider hatte ein
Angebotsmodel bei welchem die Kunden das betriebene API System in Hinischt der
Funktionen modifizieren durfte.

Aufgrund diesen Erkentnissen hat sich das Projektteam während der Evaluierung
für ein API System mit dem Namen ``Swagger'' entschieden. Es ist aktuell das
einzige API System auf dem Markt, welches den Betrieb auf einer selbst
administrierten Hardware-Umgebung zulässt.
\nl%

\subsection{Frontends}
\label{subsec:frontends}
Bevor das Projekt begann, mussten vorab zusammen mit dem Projektteam, eine
Softwareliste an möglichen Frontends erarbeitet werden. Bereits vorab wurden
folgende Softwarelösungen in das Pflichtenheft aufgenommen:
\begin{outline}
  \1 Grafana
  \1 Graphite
  \1 Zabbix-Frontend
  \end{outline}

Nach Absprache mit dem Projektteam, sind noch folgende in Frage kommende
Systeme der Evaluierungsliste aufgenommen worden.
\begin{outline}
  \1 Datadog
  \1 Gridster-D3
  \1 Netdata
\end{outline}

Das Hinzufügen von weiteren Softwarelösungen, während der Evaluierungsphase
bedarf keine weitere Zustimmung durch den Auftragegeber, sondern konnte direkt
mit dem Projektteam besprochen und aufgenommen werden. Zusätzlich zu der Liste
mit den einzelnen Softwarelösungen, wurden verschiedene Anforderungen in einem
Anforderungskatalog definiert, welche im späteren Verlauf der Planung für die
Evaluierung der einzelnen Frontends verwendet wird. Die zu evaluierende
Softwareliste besteht zum Teil aus Softwarelösungen, welche im Unternehmen von
einzelnen Projektmitgliedern bereits erfolgreich eingesetzt werden und zum
anderen aus Vorschlägen des Auftraggebers.


Folgende Softwarelösungen sind am Ende der Planungsphase in die
Evaluierungsphase aufgenommen worden:

\begin{outline}
  \1 grafana
  \1 graphite
  \1 zabbix-frontend
  \1 datadog
  \1 gridster-D3
  \1 netdata
\end{outline}
\mr%

\subsubsection{Definition eines Graphen}
\label{definition_eines_graphen}
Ein Graph besteht im wesentlichen aus mehreren Knoten und Kanten, welche auf
einem Koordinaten System angelegt sind. Mit Hilfe von zwei Knoten, bestehend
jeweils aus einer Koordinate (x/y) werden diese eindeutig zu einer Kante
definiert. Ein Linearer Graph wird genau dann visualisiert, wenn zwei Knoten
miteinander verbunden werden.

Auf der Weboberfläche werden dem User oder dem Administrator einzelne Graphen,
von z.B. CPU Auslastung, RAM Auslastung oder SSD Schreibzugriffe angezeigt.
Diese Graphen werden entweder in linerarer oder Balkenform dargestellt.
Lineare Graphen, haben eine X-Achse und Y-Achse und besitzen
zusätzlich einen Anfang und einen wachsenden Endpunkt. Er wird mittels
Metrik~\ref{subsubsection:Begriffserklärung}, welche die Weboberfläche aus den
Datenhaltungssystemen abgreift, erstellt und kann vom Administrator ebenfalls
nur für eine definierte Zeitspanne angezeigt werden. Balkendiagramme haben nur
eine X-Achse, wo der gewünschte Analysewert eingetragen ist und werden z.B. für
ausgefallene SSDs in einem bestimmten Zeitraum verwendet. Diese werden über die
Metrik aus den Datenhaltungssysteme abgegriffen und dem Administrator über eine
Übersicht angezeigt. Ein Graph bzw. Balkendiagramm visualisiert immer eine
oder mehrere Timeseries~\ref{subsubsection:Begriffserklärung}.

\subsubsection{Vorbereitung der Evaluierung}
\label{subsubsec:vorbereiten_der_evaluierung_frontend}
Damit die Evaluierungen der einzelnen Softwarelösungen durchgeführt werden
können, mussten zuvor Kriterien mit dem Projektteam in einen Anforderungskatalog
aufgenommen werden. Diese Kriterien, in Form von definierten Anforderungen,
sollen für eine besser Übersicht, während der Evaluierung dienen. Bei den
Kriterien, musste darauf geachtet werden, dass diese während der Beurteilung
der Anforderungen eine Machbarkeit und Realisierbarkeit besitzen. Nachdem die
einzelnen Kriterien zusammen mit dem Projektteam erstellt worden sind, wurden
diese im Anschluss von jedem einzelnen Projektmitglied auf die Machbarkeit und
Realisierbarkeit geprüft. Erst hiernach wurden diese dem Anforderungskatalog
aufgenommen.

Die einzelnen Kriterien wurden im nachhinein der Wichtigkeit absteigend,
wie folgt aufgelistet:
\begin{outline}
  \1 Es muss eine Authentisierung, Authentifizierung und Autorisierung
  gewährleistet werden. Dies bedeutet, dass die Daten und damit auch die
  Weboberfläche selber vor unauthorisierten Zugriff durch dritter geschützt
  sein muss. Ebenfalls muss die Verbindung, welche das Frontend nutzt, um die
  Daten abgreifen zu können vor dritter so geschützt und gesichert werden. Der
  Zugriff auf die Weboberfläche soll mit einer Transportverschlüsselung durch
  HTTPS durchgeführt werden und je nach Kundenanforderung auch eigene Client
  Zertifikate zulassen. Die Anmeldung am Frontend kann entweder über einen
  Lokalen Administrator, als auch über eine LDAP(Lightweight Directory Access
  Protocol) Anbindung verfügen, um hier z.B. Unternehmensverzeichnisse
  Anbinden zu können.
  \1 Eine inhaltlich gute und umfangreiche Community und Dokumentation über das
  Webfrontend. Der Auftraggeber und auch die Projektmitglieder selber,
  benötigen keine große Schulung mit dem Umgang des Frontends. Dies erleichtert
  zum einen den späteren Betrieb, als auch die Wartung im späteren Verlauf,
  wenn das Produkt bei einem Kunden eingesetzt wird.
  \1 Eine Leichte Anpassung, Konfiguration und direkte Ausgabe der
  Visualisierung von CPU, RAM, Netzwerk oder ähnliche Datenwerte. Hiermit ist
  gemeint das Gewährleistet werden muss, dass  die einzelnen Graphen schnell
  und einfach (Endanwender spezifisch) direkt angepasst werden können.  Ebenso
  muss die Anbindung an eventuell bereits schon vorhandene Datenbanksysteme
  einfach durchgeführt werden können.
  \1 Die Datensicherung ist bei dem Frontend ein wesentlicher Aspekt.  Dabei
  muss die Weboberfläche, bereits schon Möglichkeiten bieten, eine
  Datensicherung des Dashboards durchführen zu können.  Das Dashboard,
  beeinhaltet alle Graphen und vorkonfigurierte Werte. Diese sollen über z.B.
  ein externes System (Dateifreigabe Server o.a.) abgelegt werden und können
  somit einfach dupliziert und gesichert werden.
  \1 Plugin Erweiterung. Das Frontend, muss eine Plugin Erweiterung
  unterstützen. Es dient dazu, das im späteren Verlauf, wenn das Produkt
  bereits beim Kunden eingesetzt wird, auf bestimmte Kundenwünsche direkt
  eingehen zu können. Diese können dann Mittels bereits schon zur Verfügung
  gestellte Plugins, z.B. in der Community oder aber durch selbst programmierte
  Plugins realisiert werden. Die Plugins werden, bzw sollen in Javascript
  geschrieben werden können. Die Weboberfläche sollte jedoch auch andere
  Sprachen unterstützen, um so eine Unabhängigkeit von Entwicklern
  gewährleisten zu können. Unternehmen müssen so nicht auf spezielle
  Entwickler von bestimmten Sprachen zurückgreifen.
  \1 Die genutzten Softwärelösungen müssen eine Open Source Lizenz besitzen, um
  hier unabhängig von kostenpflichtigen Lizenzen und Copyright Rechten zu sein.
  Ebenfalls ist eine Open Source Software nötig, da hier der Quelltext der
  Software angepasst und verändert werden darf.
\end{outline}
\mr%

\subsubsection{Durchführung Evaluierung Frontend}
\label{subsubsec:durchfuehrung_evaluierung_frontend}
Für die Durchführung der Evaluierung der ausgewählten Frontends aus der obigen
Liste~\ref{subsec:frontends} wurden die entsprechenden Kriterien zur
Evaluierung aus Punkt~\ref{subsubsec:vorbereiten_der_evaluierung_frontend}
verwendet.


Bevor die Evaluierung der einzelnen Softwarelösungen durchgeführt werden konnte,
wurden vorab bereits eine vielzahl an Informationen über die einzelnen
Softwarelösungen mittels Internetrecherche und Fachzeitschriften eingeholt.
Zusätzlich wurden die einzelnen Softwarelösungen auf zwei Projektmitglieder
aufgeteilt, um die Evaluierung und damit auch die Projektplanung zeitlich zu
verkürzen.

Nachdem die Analyse der Softwarelösungen von den einzelnen Projektmitglieden
abgeschlossen wurde, wurden die gesammelten Resultate Herrn Reuter zur
Verfügung gestellt. Mit diesen Resultaten konnte Herr Reuter eine Auswertung
aller Softwarelösungen durchführen, welche im nachfolgenden Punkt aufgelistet
wurden.

Hierbei ist aufgefallen, dass für die Softwarelösung `Gridster-D3' eine
kostenpflichtige jährliche Lizenz benötigt wird und der Quellcode nicht
angepasst werden kann. Somit fällt diese Softwarelösung aus der weiteren
Evaluierung aus, da diese Zwei Anforderungen bereits vorab schon ein
Auschlusskriterium sind.

Im Nachfolgenden Punkt sind die einzelnen Softwarelösungen mit den einzelnen
Anforderungen und Evaluierungsergebnissen aufgelistet:


\begin{outline}
  \1 Grafana
  + Authentisierung, Authentifizierung und Autorisierung
  + Gute Community und eine vielzahl an Dokumenten
  + Leichte Anpassungen an Graphen und Einstellungen
  + Dashboards können auf externen Server gesichert werden
  + Grafana kann mittels bereitsgestellter API arbeiten
  + Bietet eine Plugin Erweiterung an

  + Multiplattform Support
  + OpenSource

  \textasciitilde Webdesign kann nicht angepasst werden
  \textasciitilde Webtemplate nur aus zwei auswählbar (dark/white)

  -
  -
  -

  \1 Graphite
  + Authentisierung, Authentifizierung und Autorisierung
  + Gute Community und eine vielzahl an Dokumenten
  +


  \1 Zabbix-frontend



  \1 Datadog



  \1 Gridster-D3
  +
  +
  +

  \textasciitilde
  \textasciitilde

  - Lizenz muss Monatlich erworben werden
  -


  \1 Netdata



\end{outline}
\mr%

\section{Realisierung}

\section{Userstories}
Im Punk~\ref{subsec:agile_vorgehensweise} wurde bereits kurz auf Userstories
eingegangen. Im folgenden wird die generelle Vorgehensweise erklärt, sowie die
Implementierung und Realisierung der Userstories in diesem Projekt.

Zu jeder Userstory wird ein Drahtgittermodell (Englisch: Wireframe) erstellt.
Dies ist eine schematische Zeichnung der angefragten Änderung. Bei Änderungen
an einer Webseite wird eine Nachbildung der Seite gezeichnet, bei
Datenbankänderungen eine Tabelle. Im Anschluss darauf erfolgt die Zerlegung
(Englisch: Decomposition) des Wireframes in die einzelnen
Informationsbestandteile. Als Beispiel kann angenommen werden, dass eine
Userstory einen zusätzlichen Graphen auf einer Webseite anfordert.
Ausschlaggebend für die Zerlegung sind folgende Fragen:

\begin{outline}
  \1 Werden zusätzliche Daten benötigt um die Userstory zu implementieren oder
  reichen die vorhandenen Daten die bereits auf der Webseite genutzt werden?
  \1 Wo kommen diese Daten her?
  \1 Wer liefert die Daten bzw.\ wird dafür eine Genehmigung benötigt?
  \1 Werden bereits genutzte Daten nicht mehr benötigt?
  \1 Ist die Änderung Atomar oder kann sie weiter zerlegt werden?
\end{outline}

Daraus ergeben sich mehrere Änderungen die am Projekt gemacht werden müssen um
die Userstory zu implementieren. Für jede Änderung wird ein Ticket erstellt.
Ziel des ganzen ist es, eine komplexe Userstory, die einen einzelnen
erfahrenen Entwickler lange mit der Implementierung beschäftigt, möglichst weit
herunterzubrechen. Die entstandenen Teilaufgaben erfordern größtenteils keinen
erfahrenen Entwickler, dieser ist nur noch für einige wenige Tickets notwendig.
Ein weiterer Vorteil ist, dass nun mehrere Leute parallel an den einzelnen
Tickets arbeiten können.
\tm%

\subsection{Userstory 1}

\subsection{Userstory 2}

\subsection{Userstory 3}

\section{Fazit}

\printglossaries%

\printbibliography[heading=bibnumbered]

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis-de"
%%% End:
