Data Warehousing for Cloud Computing Metrics -
Functional Specification Document


Introduction
Our Partner for this project is the company Puppet Inc. (hereafter Puppet), who acts as the contracting authority. The company is represented by Steve Quin and David Schmitt. Contractors are Tim Meusel, Nikolai Luis and Marcel Reuter. Tim Meusel will also act as a team leader. The project is going to be realized as a part of the final project for a study program at the Heinrich-Hertz-Europakolleg. The lecturer Dirk Stegemann is going to supervise the project as a representative of the school, he is also responsible for the final evaluation. The course of studies is ‘Staatlich geprüfter Informatiker’ undertaken between 2014 and 2018.


Virtualization technologies are used at cloud providers to partition the resources of a physical system into multiple pieces. Physical resources are shared between all virtual instances on a host. The goal of the different providers is it to host as many virtual machines as possible on each physical server. Due to overcommit, from time to time a single virtual instance can consumes too many resources, interfering with the intended functionality and performance of other virtual machines on the same host. Therefore, the usage patterns and resource requirements of each machine has to be cleanly documented so it can be analysed. The gathered information will then be used for optimisation and tailoring of the platform as a whole.


Task
The goal of this project is to create a working open source solution. This is divided into three major subtasks:
1. Collect all  required information from each virtual instances on the host system, spool them and then periodically send them to the database system.
2. Set up a suitable database software which is scalable and provides a certain level of redundancy. The goal is to save the information of at least 10.000[a] virtual instances.
3. Provide a web interface where customers can see visualizations of their utilized resources. Furthermore an API is required to expose the data to different kinds of users. A user story survey for the three types of users (customer, administrator, manager) will be conducted with different partners. This will help the project team figure out what kind of, possibly preprocessed and aggregated data needs to be available via the API. 


The data has to be stored in one or multiple databases forming a data store. Complex queries will be executed on the datastore, therefore a data warehouse approach should be considered and analysed. The data from the virtual instances will be collected in a regular time frame from 1 Second, up to 5 Minutes. The interval of the time frame, can be defined by the user over the Web-UI. [b] 


There are already finished open source projects providing the listed, isolated, specific functionality. This applicability of those solutions to the given task have to be evaluated.






Differentiation of the system
There are already several open source software projects that claim to provide a solution for one of the subtasks outlined above. The fitness of the following software products for the given tasks will be evaluated: 


Data Acquisition Systems:
* collectd with virt plugin
* coreutils
* zabbix-agent
* python-diamond
* sysstat
* atop
* logtash
* riemann


Database systems:
* elasticsearch
* cassandra
* postgres
* OpenTSDB
* KNIME
* impala
* hadoop
* hive


Frontends:
* grafana
* graphite
* zabbix-frontend


For both the exploration and the production phase, composition of the generic components listed  above is preferred over a domain- and application specific reimplementation with a possibly limited list of features and test coverage. The two companies Host Europe GmbH and Travis CI GmbH provide the team with free testing- and development- environments.




Description of interfaces
There are several software interfaces in this project. The first interface collects and exports information over the virtual machine on the physical hosts. The host provides detailed usage statistics for each virtual instance. The network interface of the host will be used to send the gathered data to the database via TCP or UDP. In case of performance problems, an optional queuing or caching service might be required in front of the database. In this case the host will communicate with this service instead of the database. There are several possible solutions for the communication channel between the physical server and  the data storage systems:
* The host directly communicates with a single database system
* The host sends data to a loadbalancer which is placed in front of one to multiple database servers
* The host talks to a system that runs an ETL process. This process will import the data into a data storage
* The host talks to a messagebus which will save the data in the data storage
As the process is intentionally kept open and explorative in nature, it is possible that during the project, based on the validation and results available from testing with prototypes based on different data storage solutions, new approaches and storage-interfaces will emerge. Technicians like data analysts or persons from the C-level need to be able to request the data in exchangeable format used by common analysis and data processing tools. These formats will be defined in the user story survey. 

Every interface takes over the role of a sender and/or receiver, as documented in the list below:
* The virtual instance on a physical node
   * Sender
* The physical node
   * Sender and receiver
* The data storage
   * Receiver
* The API
   * Receiver of a datarequest, sender for data
* The webinterface
   * Sends data requests to the data storage,  along with a generated view to the terminal device
* The terminal device
   * Receiver


Problem analysis
There are two major problems that the project team needs to take care of. First of all, it needs to cope with the amount of data produced by every single node. The data will be transferred via a network that is shared with other services. The network must not be overallocated and the impact on the other services on the network must be minimized. Furthermore the resource footprint of the data acquisition software on the nodes must be minimal in order to not harm the performance of the running virtual machines.


________________


External influences
The software needs to be build in a way that supports long continuous uptime periods. It must be able to run unsupervised without regular intervention from system administrators. 


Expected behaviour and behaviour during a disturbance
The datacenter provider has to deal with power outages. A disruption on the central services like data storage should be absorbed by caching or standby nodes. An outage on a single physical host will kill all virtual machines on it, there is no way to workaround this. The operator of the host has to deal with this and not the project team.


Feasibility of the project
a) organisational/economically
The required amount of time will be estimated with the help of the ticket system Jira and agile development methods. The milestones will be planned together with Puppet Inc. Apart from the students involved and listed in the introduction, there are no manpower costs in this project. 


b) technical view
The required hardware to power this project including all development & testing tasks will be provided Puppet Inc. or other partners. The final approval at the end of the project can be made on the provided platforms.


Scope of the Functional Specification Document
This document is to be considered effective and valid after it received joint approval from both  Puppet Inc. and the project group. Further changes need to be accepted by the project team, Puppet Inc. and the lecturer from the Heinrich-Hertz-Europakolleg. Tim Meusel is the project groups representative for any such project related questions that may arise.


Project Organisation
Besides the roles of the contracting authority (Puppet Inc.) and the supervising lecturer, a distribution of roles and responsibilities among the project team members in required. Even though all team members will naturally be familiar with each of the three major components of the project on a basic level, each part will receive an module-officer who is ultimately responsible for the specific component:
* Team leader, Tim Meusel, responsible for:
   * Development of the data gathering process
   * Transport of the data between the place of gathering and the data storage
* Project member, Nikolai Luis, responsible for:
   * Development of the data storage part and API
* Project member, Marcel Reuter, responsible for:
   * Development and automation of the web frontend
Phase planning
There won’t be detailed schedule for the planned stages at the beginning of the project. The project will be managed with agile methods. This allows the project team to work with short sprints that don’t need detailed planned phases from the beginning until the end. Every sprint will be planned and managed by the team leader. While agile, the project however still has the following stages of conventional software-engineering models:
* Analysis
* Design/Prototyping
* Implementation
* Testing/Bugfixing
* Documentation
* Acceptance stage


Milestones will be defined by the project team in agreement with Puppet Inc. or with the lecturer.


Procedure control
Several different software solutions will be used to track the progress of the project. They will allow every involved person to gather information about the current status. “Confluence” will be used for documentation, “Jira” for tracking issues and “git” to manage sourcecode and related artifacts such as build scripts, etc..
The project team will create weekly reports on the progress achieved in the past weeks.




Risk Register
We will work together with partner companies. Among other things they will provide us with real world data from their systems that we can use in our tests. It is possible that they will be unable to provide the requested data in the desired timeframe or a lack of interest in the project and changed priorities. In this case we have to generate and mock data by ourself. Mocked data is never as good as real data, it is possible that this distorts our tests and leads to wrong conclusions. A second risk is the human factor of the project, e.g. illness and the subsequent mid to long term drop out of  one of our project members.
[a]10.000 virtual instances
[b]please check this